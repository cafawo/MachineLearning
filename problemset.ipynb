{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Problem Set\n",
    "\n",
    "## Overview\n",
    "\n",
    "The focus of this problem set is on analyzing textual data from scientific papers. The primary aim is to develop an analysis pipeline that reads, pre-processes, and analyzes textual data.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "### Data sourcing\n",
    "\n",
    "The first stage involves sourcing and reading the textual content of scientific papers. You find a few example pdf files in ``data/``. Please download additional paper of your choice. Make sure you analyze a total of at least 6 papers.\n",
    "\n",
    "Use an appropriate PDF reading library or tool to programmatically extract the text. You can find an example in ``problemset.ipynb``, however, you are free to use any Python library you like.\n",
    "\n",
    "### Pre-processing\n",
    "\n",
    "Pre-processing is a critical step aimed at cleaning and preparing the text data for analysis. This stage involves:\n",
    "\n",
    "* Removing punctuation, numbers and special characters using regular expressions.\n",
    "* Converting all the text to a uniform case (usually lower case) to ensure that the analysis is not case-sensitive.\n",
    "* Stop word removal, i.e. eliminating commonly used words (e.g., 'and', 'the', 'is') that do not contribute significantly to the overall meaning and can skew the analysis.\n",
    "* Other potential pre-processing steps might include stemming and lemmatization, depending on the specific requirements and goals of the analysis. (optional)\n",
    "\n",
    "### Analysis\n",
    "\n",
    "The final stage is the analysis of the pre-processed text to extract meaningful context. This may involve:\n",
    "\n",
    "* Frequency Analysis: Determining the most commonly occurring words or phrases, which can provide initial insights into the primary focus areas of the papers. Consider, e.g. a word cloud as a visualization.\n",
    "* Contextual Analysis: Using more advanced NLP techniques such as Word Embedding or Topic Modeling to understand the context of the papers.\n",
    "* Summarization: Employing algorithms to generate concise summaries of the papers, capturing the key points and findings.\n",
    "\n",
    "Pick any method that you like (you are allowed to use ChatGPT's API as well).\n",
    "\n",
    "## Submission\n",
    "\n",
    "Please note that the focus of this case is on the execution of the task and NOT the results. The methods chosen are therefore of secondary importance and up to you, however, the results must be reproducible with the submitted code. You should focus on clean coding, commenting and the appropriate use of Git/GitHub. Follow the guidelines laid out in [PEP 8 – Style Guide for Python Code](https://peps.python.org/pep-0008/).\n",
    "\n",
    "Your solutions should be contained in one jupyter notebook ``problemset.ipynb``.\n",
    "\n",
    "Make sure to read the \"Grading\" section at: (https://github.com/iwh-halle/ML2024?tab=readme-ov-file#grading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting text from PDF files\n",
    "\n",
    "**(This is a suggestion, remove the code if you do not need it ...)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install pdfminer.six if you haven't already\n",
    "# You can install it using conda or pip, see \n",
    "  # https://anaconda.org/conda-forge/pdfminer.six\n",
    "  # https://pypi.org/project/pdfminer.six/\n",
    "\n",
    "# Step 2: Import the required modules\n",
    "import os\n",
    "import re\n",
    "from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bajari-MachineLearningMethods-2015.pdf', 'cesifo1_wp6504.pdf', 'SSRN-id3567724.pdf']\n"
     ]
    }
   ],
   "source": [
    "# Files in the data folder\n",
    "pdf_files = os.listdir(path='data')\n",
    "print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your PDF file\n",
    "pdf_file_path = os.path.join('data', pdf_files[2])\n",
    "\n",
    "# Extract text\n",
    "extracted_text = extract_text(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Let me get back to you” –\n",
      "A machine learning approach to measuring\n",
      "non-answers∗\n",
      "\n",
      "Andreas Barth†\n",
      "\n",
      "Sasan Mansouri‡\n",
      "\n",
      "Fabian Woebbeking§\n",
      "\n",
      "April 1, 2022\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the beginning of the extracted text\n",
    "print(extracted_text[0:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Let me get back to you    A machine learning approach to measuring non answers   Andreas Barth   Sasan Mansouri   Fabian Woebbeking   April          \n"
     ]
    }
   ],
   "source": [
    "# Regex to remove all non-alphabetical characters and replace them with a space\n",
    "processed_text = re.sub('[^a-zA-Z]', ' ', extracted_text)\n",
    "\n",
    "print(processed_text[0:150])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "title": "Machine Learning"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
